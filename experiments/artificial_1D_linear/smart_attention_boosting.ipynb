{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x127c58310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data import artificial_1D_linear as data\n",
    "from experiments.artificial_1D_linear.documentation import (\n",
    "    evaluate,\n",
    "    plot_data_split,\n",
    "    plot_predictions,\n",
    ")\n",
    "from models import SmartAttentionLayer\n",
    "\n",
    "from experiments.artificial_1D_linear.smart_fed_avg_util import (\n",
    "    train_client,\n",
    "    register_client_test_losses,\n",
    ")\n",
    "from utils.general import get_logging_dir\n",
    "\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE: torch.device = torch.device(\"cpu\")\n",
    "NUM_CLIENTS = 5\n",
    "\n",
    "COMMUNICATION_ROUNDS = 20\n",
    "BOOSTING_ROUNDS = 10\n",
    "CLIENT_EPOCHS = 100\n",
    "\n",
    "SPLIT_TYPE = \"interval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_IDs = range(NUM_CLIENTS)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "INPUT_FEATURES = 1\n",
    "OUTPUT_FEATURES = 1\n",
    "PRED_ARCHITECTURE = [5, 5, 5, 5]\n",
    "INPUT_IMPRTNC_ARCHITECTURE = [5, 5]\n",
    "CLIENT_IMPRTNC_ARCHITECTURE = [5, 5]\n",
    "SIMILARITY_THRESHOLD = 30\n",
    "\n",
    "LOSS_FN = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_hyperparameters(writer, last_loss):\n",
    "    writer.add_hparams(\n",
    "        {\n",
    "            \"client_epochs\": CLIENT_EPOCHS,\n",
    "            \"num_clients\": NUM_CLIENTS,\n",
    "            \"communication_rounds\": COMMUNICATION_ROUNDS,\n",
    "            \"split_type\": SPLIT_TYPE,\n",
    "            \"pred_architecture\": str(PRED_ARCHITECTURE),\n",
    "            \"input_imprtnc_architecture\": str(INPUT_IMPRTNC_ARCHITECTURE),\n",
    "            \"client_imprtnc_architecture\": str(CLIENT_IMPRTNC_ARCHITECTURE),\n",
    "            \"similarity_threshold\": SIMILARITY_THRESHOLD,\n",
    "            \"boosting_rounds\": BOOSTING_ROUNDS\n",
    "        },\n",
    "        {\n",
    "            \"MSE Test\": last_loss,\n",
    "        },\n",
    "        run_name=\".\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SmartAttentionBoosting\n",
    "model_name = f\"SmartAttentionBoosting_{NUM_CLIENTS}clients_{SPLIT_TYPE}-split\"\n",
    "\n",
    "writer = SummaryWriter(get_logging_dir(model_name, \"artificial_1D_linear\"))\n",
    "\n",
    "\n",
    "global_model = SmartAttentionBoosting(\n",
    "    INPUT_FEATURES,\n",
    "        OUTPUT_FEATURES,\n",
    "        NUM_CLIENTS,\n",
    "        PRED_ARCHITECTURE,\n",
    "        INPUT_IMPRTNC_ARCHITECTURE,\n",
    "        CLIENT_IMPRTNC_ARCHITECTURE,\n",
    "        device=DEVICE)\n",
    "\n",
    "client_train_dataloaders = data.get_client_train_dataloaders(\n",
    "    NUM_CLIENTS, SPLIT_TYPE, BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "plot_data_split(client_train_dataloaders, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cooling_off_epoch(cr: int):\n",
    "    return cr > COMMUNICATION_ROUNDS // 2\n",
    "\n",
    "\n",
    "for br in range(BOOSTING_ROUNDS):\n",
    "    global_model.add_new_boosting_layer()\n",
    "\n",
    "    for cr in range(COMMUNICATION_ROUNDS):\n",
    "\n",
    "        clients = [\n",
    "            global_model.get_client_model(\n",
    "                client_id, add_noise=(not is_cooling_off_epoch(cr))\n",
    "            )\n",
    "            for client_id in CLIENT_IDs\n",
    "        ]\n",
    "        # train each client individually\n",
    "\n",
    "        for client_no, client in zip(CLIENT_IDs, clients):\n",
    "            train_client(\n",
    "                client_no=client_no,\n",
    "                client_model=client,\n",
    "                data_loader=client_train_dataloaders[client_no],\n",
    "                loss_fn=LOSS_FN,\n",
    "                no_epochs=CLIENT_EPOCHS,\n",
    "                communication_round=br * COMMUNICATION_ROUNDS + cr,\n",
    "                writer=writer,\n",
    "                device=DEVICE,\n",
    "            )\n",
    "\n",
    "        register_client_test_losses(\n",
    "            clients=clients,\n",
    "            client_ids=CLIENT_IDs,\n",
    "            writer=writer,\n",
    "            communication_round=br * COMMUNICATION_ROUNDS * CLIENT_EPOCHS\n",
    "            + cr * CLIENT_EPOCHS,\n",
    "            device=DEVICE,\n",
    "            plot_client_predictions=True\n",
    "        )\n",
    "        global_model.register_new_client_models(\n",
    "            clients,\n",
    "            similarity_threshold_in_degree=(\n",
    "                SIMILARITY_THRESHOLD if not is_cooling_off_epoch(cr) else 181\n",
    "            ),\n",
    "            method=\"combine\" if not is_cooling_off_epoch(cr) else \"average\",\n",
    "        )\n",
    "        global_model.to(DEVICE)\n",
    "\n",
    "        writer.add_scalar(\n",
    "            \"test_loss\",\n",
    "            evaluate(global_model, device=DEVICE),\n",
    "            br * COMMUNICATION_ROUNDS * CLIENT_EPOCHS + cr * CLIENT_EPOCHS,\n",
    "        )\n",
    "\n",
    "        plot_predictions(\n",
    "            global_model,\n",
    "            model_name,\n",
    "            writer,\n",
    "            epoch=br * COMMUNICATION_ROUNDS + cr,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "\n",
    "        print(global_model)\n",
    "\n",
    "plot_predictions(global_model, model_name, writer, device=DEVICE)\n",
    "register_hyperparameters(writer, last_loss=evaluate(global_model))\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_model.query_network.full_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client in clients:\n",
    "    print(client.prediction_network.full_representation())\n",
    "    print(client.prediction_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
