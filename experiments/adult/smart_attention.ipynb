{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.general import get_logging_dir\n",
    "import torch\n",
    "import utils\n",
    "import models\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils.training import get_loss_fn, get_optimizer, train_one_epoch\n",
    "from utils.general import get_logging_dir, make_values_scalar\n",
    "\n",
    "import data.adult\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "MAX_THETA = 181 #degree -> more than any two vectors can be apart\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    data.adult.get_dataset(\"test\"), batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a84c3859664939b1ac72d3011f62ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770f8ebf220d4149935045dec27d5d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cefb2724d99439ca460a5c577e5a518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdb1f9f30b84a22be44dd088d216aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69198fe6eaf847ac8e5ca75464e0d753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049a933687ea4fdbafe675103b3f7f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0d0335a0cc473c9cb4600dfc52bc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d939a0a9714d58888888e4d32cd76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65a7ddd40914b14b5df5fb4c536f0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d66ce5f3f1482f912f7e73548e5103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dead4332394b339715d1680c9f724d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bc0fa2606b4682bd83d9b9e3630460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd0e8d008b443d9a3fc77a5dff058af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adfa264074a42ca95619f19f8c72f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b1e3c405944930baf0dee949604472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94501cbfafc74fa396a1067b11dcf49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0aa0a2098e465e8ba4316827e63950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625d2111200a42718178bb138bf0ee5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279ab1ae7a1748ed886c3dcedc975489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe292e16ca09474697bc56307efe425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c637587bba374d3daf7d741b5caae915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipp/Documents/Studium/Informatik/Semester 2/Federated Learning/Project/models/multi_output_net.py:174: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.shape[0] != self._cached_batch_size:\n",
      "/Users/philipp/Documents/Studium/Informatik/Semester 2/Federated Learning/Project/models/smart_attention_layer.py:147: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  scale_factor = 1 / sqrt(query.size(-1))\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from models import SmartAttentionLayer\n",
    "\n",
    "\n",
    "hparams = {\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": \"bce_with_logits\",\n",
    "    \"batch_norm\": \"---\",\n",
    "    \"layer_norm\": \"---\",\n",
    "    \"dropout_rate\": \"---\",\n",
    "    \"client_epochs\": 1,\n",
    "    \"num_clients\": 10,\n",
    "    \"communication_rounds_training\": 1,\n",
    "    \"communication_rounds_aligning\": 1,\n",
    "    \"client_data_distribution\": \"random\",\n",
    "    \"similarity_threshold_in_degree (theta)\": 40,\n",
    "    \"aligning_method\": \"combine\",\n",
    "    \"added_noise_in_training\": False,\n",
    "}\n",
    "prediction_network_architecture: list[int] = [40, 40, 40, 20, 10]\n",
    "input_importance_network_architecture: list[int] = [10, 10, 10]\n",
    "client_importance_network_architecture: list[int] = [10, 10, 10]\n",
    "\n",
    "\n",
    "hparams[\"prediction_network_architecture\"] = str(prediction_network_architecture)\n",
    "hparams[\"input_importance_network_architecture\"] = str(\n",
    "    input_importance_network_architecture\n",
    ")\n",
    "hparams[\"client_importance_network_architecture\"] = str(\n",
    "    client_importance_network_architecture\n",
    ")\n",
    "\n",
    "global_model = SmartAttentionLayer.initialize_from_scratch(\n",
    "    107,\n",
    "    1,\n",
    "    hparams[\"num_clients\"],\n",
    "    None,\n",
    "    prediction_network_architecture,\n",
    "    input_importance_network_architecture,\n",
    "    client_importance_network_architecture,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "\n",
    "dataloaders = data.adult.get_client_train_dataloaders(\n",
    "    hparams[\"num_clients\"], hparams[\"client_data_distribution\"], BATCH_SIZE, True\n",
    ")\n",
    "\n",
    "\n",
    "writer = SummaryWriter(get_logging_dir(\"smart_attention\", \"adult\"))\n",
    "\n",
    "\n",
    "loss_fn = get_loss_fn(hparams[\"loss_fn\"])\n",
    "\n",
    "\n",
    "for communication_round in tqdm(\n",
    "    range(\n",
    "        hparams[\"communication_rounds_training\"]\n",
    "        + hparams[\"communication_rounds_aligning\"]\n",
    "    )\n",
    "):\n",
    "    is_aligning_round = communication_round >= hparams[\"communication_rounds_training\"]\n",
    "    client_models = {\n",
    "        client_id: global_model.get_client_model(\n",
    "            client_id, hparams[\"added_noise_in_training\"] and not is_aligning_round\n",
    "        )\n",
    "        for client_id in range(hparams[\"num_clients\"])\n",
    "    }\n",
    "    optimizers = {\n",
    "        client_id: get_optimizer(\n",
    "            hparams[\"optimizer\"],\n",
    "            hparams[\"learning_rate\"],\n",
    "            client_models[client_id].parameters(),\n",
    "        )\n",
    "        for client_id in range(hparams[\"num_clients\"])\n",
    "    }\n",
    "\n",
    "    for m in client_models.values():\n",
    "        m.to(DEVICE)\n",
    "\n",
    "    for client_id in range(hparams[\"num_clients\"]):\n",
    "\n",
    "        for epoch in tqdm(range(hparams[\"client_epochs\"]), leave=False):\n",
    "            epoch_loss = train_one_epoch(\n",
    "                client_models[client_id],\n",
    "                dataloaders[client_id],\n",
    "                optimizers[client_id],\n",
    "                loss_fn,\n",
    "                DEVICE,\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                f\"Loss/train/client{client_id}\",\n",
    "                epoch_loss,\n",
    "                communication_round * hparams[\"client_epochs\"] + epoch,\n",
    "            )\n",
    "\n",
    "    global_model = SmartAttentionLayer.get_global_model(\n",
    "        list(client_models.values()),\n",
    "        hparams[\"similarity_threshold_in_degree (theta)\"] if is_aligning_round else MAX_THETA,\n",
    "        method=hparams[\"aligning_method\"] if is_aligning_round else \"combine\",\n",
    "    )\n",
    "    y_hats, ys = utils.evaluation.evaluate(\n",
    "        global_model, test_dataloader, from_logits=True, return_outputs_only=True\n",
    "    )\n",
    "    writer.add_scalar(\n",
    "        \"Loss/test\",\n",
    "        loss_fn(y_hats.to(torch.float), ys.to(torch.float)).item(),\n",
    "        communication_round * hparams[\"client_epochs\"],\n",
    "    )\n",
    "    writer.add_scalar(\n",
    "        \"total_params\",\n",
    "        summary(global_model).total_params,\n",
    "        communication_round * hparams[\"client_epochs\"],\n",
    "    )\n",
    "\n",
    "\n",
    "metrics = utils.evaluation.evaluate(global_model, test_dataloader, from_logits=True)\n",
    "\n",
    "writer.add_hparams(hparams, dict(metrics), run_name=\".\")\n",
    "\n",
    "writer.add_text(\"Model Summary\", str(summary(global_model, input_size=(1, 107))))\n",
    "writer.add_text(\"hparams\", json.dumps(hparams, indent=4))\n",
    "\n",
    "dummy_input = torch.randn(1, 107)  # Example input\n",
    "writer.add_graph(global_model, dummy_input)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
